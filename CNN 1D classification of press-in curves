#1. import the dataset from excel
import pandas as pd
df = pd.read_excel("../Datens√§tze/BA_DATENSATZ_2.xlsx", sheet_name=3)


#2. convert the dataset in an array
import numpy as np

anzahl_zeile = 551
spalten_start = 62
spalten_ende = 332
anzahl_spalte = spalten_ende - spalten_start

# weg in mm
x_weg = np.array(df.iloc[552, spalten_start:spalten_ende])

# kraft in kN
y_kraft = np.zeros((anzahl_zeile) * anzahl_spalte).reshape((anzahl_zeile), anzahl_spalte)

# speichern kraftverlauf in einer matrix
for i in range(0, anzahl_zeile):
    y_kraft[i] = df.iloc[i, spalten_start:spalten_ende]
    
    
#3. create the feature and labels
# X: Kraftverlaufsmatrix
X = y_kraft

# Y: label der Klassen
Y = df["Klassennummer"].values[:anzahl_zeile]


#4. convert the labels with one-hot-coding

from keras.utils import to_categorical
Y = to_categorical(Y)


#5. shuffle the features and labels

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=1, test_size=0.2, shuffle=True)


#6. build a cnn 1d model

from keras.models import Sequential
from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout
from keras.callbacks import EarlyStopping

es = EarlyStopping(monitor="loss", patience=50, verbose=1)

def get_model():
            
    model = Sequential()
    
    model.add(Conv1D(16, kernel_size=8, activation="relu", input_shape=(spalten_ende - spalten_start, 1)))
    model.add(MaxPooling1D(3))
   
    model.add(Conv1D(16, kernel_size=8, activation="relu"))
    model.add(MaxPooling1D(3))
    
    model.add(Conv1D(16, kernel_size=8, activation="relu"))
    model.add(Dropout(0.25))

    model.add(Flatten())

    model.add(Dense(200, activation="relu"))
    model.add(Dense(100, activation="relu"))
    model.add(Dropout(0.33))
    model.add(Dense(7, activation="softmax"))
    
    model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

    return model

model = get_model()


#7. train an evaluate the model
history = model.fit(x_train.reshape(-1, anzahl_spalte, 1), y_train, epochs=400, batch_size=1024, 
                    validation_split=0.2, callbacks=[es])

print(model.evaluate(x_test.reshape(-1, anzahl_spalte, 1), y_test))


#8. plot a loss and accuracy graph to control the training precess
plt.figure(figsize=(10,7))
plt.title('Loss CNN', fontsize=30)
plt.plot(history.history['loss'], label='train', linewidth=3)
plt.plot(history.history['val_loss'], label='val', linewidth=3)
plt.legend(loc='upper right', fontsize=30)
plt.tick_params(axis="x", labelsize=16)
plt.tick_params(axis="y", labelsize=16)
plt.show()

plt.figure(figsize=(10, 7))
plt.title('Accuracy', fontsize="xx-large")
plt.plot(history.history['accuracy'], label='train', linewidth=3)
plt.plot(history.history['val_accuracy'], label='val', linewidth=3)
plt.legend(loc='upper left', fontsize="xx-large")
plt.show()


#9. use confusion matrix to evaluate your model and find the weakness of your buld model
from pandas_ml import ConfusionMatrix
pred_classes = model.predict_classes(x_test.reshape(-1, anzahl_spalte, 1))

y_converted = np.argmax(y_test, axis=1)

ConfusionMatrix(y_converted, pred_classes)


from sklearn.metrics import classification_report
report = classification_report(y_converted, pred_classes)
print(report)



